<!DOCTYPE html>
<html lang="en-US">
  <head>
  
    <meta charset="UTF-8" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#157878" />
    <meta
      name="apple-mobile-web-app-status-bar-style"
      content="black-translucent"
    />
    <link rel="stylesheet" href="./assets/css/style.css?v=" />
    <style>
      @media screen and (max-width: 600px) {
        .speaker-info {
          flex-direction: column;
        }
        .speaker-image {
          width: 100%;
          max-width: 300px;
          margin: 0 auto 1rem;
        }
        .speaker-details {
          width: 100%;
        }
      }
    </style>
  </head>
  <body>
    <a id="skip-to-content" href="#content">Skip to the content.</a>

    <header class="page-header" role="banner">
      <h1 class="project-name">Computing for Well-being (WellComp 2025)</h1>
      <h2 class="project-tagline">Workshop at UbiComp/ISWC 2025</h2>

      <a href="./index.html" class="btn">Home</a>

      <a href="./cfp.html" class="btn">Call for Papers</a>

      <a href="./organizers.html" class="btn">Organizers</a>

      <a href="./speakers.html" class="btn">Speakers</a>

      <a href="./committee.html" class="btn">Program Committee</a>

     <a href="./schedule.html" class="btn">Program</a>

      <a href="./papers.html" class="btn">Accepted Papers</a>
    </header>

    <main id="content" class="main-content" role="main">
      <h1 id="call-for-papers">Speakers</h1>
      <!-- <p><i>(TBC)</i></p> -->
      <div class="speaker-info" style="display: flex; align-items: flex-start; margin-bottom: 2rem;">
        <div class="speaker-image" style="flex: 0 0 300px; margin-right: 2rem;">
          <img src="./assets/images/kvl.jpeg" alt="Kristof Van Laerhoven" style="width: 100%; max-width: 300px; border-radius: 8px;" />
        </div>
        <div class="speaker-details" style="flex: 1;">
          <h2><a href="https://ubi29.informatik.uni-siegen.de/usi/team_kvl.html" target="_blank" rel="noopener">Kristof Van Laerhoven</a></h2>
          <p>University of Siegen</p>
          <p><b>Title:</b> The Data Dilemma in Designing Low-Cost, High-Precision Wearables for Users’ Wellness Tracking</p>
          <p style="text-align: justify;"><b>Abstract:</b> When designing wearables for individuals’ everyday wellness tracking, balancing device affordability with the need for accurate and privacy-preserving interpretation of sensor data is key. I will address in this talk recent works that directly address this by exploring strategies that span sensor design, data annotation, multimodal fusion, and privacy-aware processing. Own work on wearable sensing such as DeepPPG, WESAD, or WEAR illustrate the impact that sensor-specific methods can have, while studies in (federated) fitness tracking, hand washing, or epilepsy seizure detection show the challenges and promises in actual deployments. I’ll finally show some hands-on examples of embedded wearable platforms and the importance of open-source, reproducible tools.</p>
          <p style="text-align: justify;"><b>Bio:</b> Kristof is a professor for Ubiquitous Computing at the University of Siegen (in Germany) and interested for a long time in wearable and embedded sensing systems research, as well as activity and affect recognition. After his studies in Brussels, Belgium, he obtained his PhD with Hans Gellersen at Lancaster University (UK) and after a PostDoc with Bernt Schiele at the Technical University of Darmstadt (Germany), obtained an Emmy Noether Research grant, after which he became a professor for embedded systems at the University of Freiburg (Germany). He was recently co-chair of UbiComp/ISWC 2023, has in the past chaired the ISWC Steering Committee, and currently is an Editor for the ACM IMWUT journal.<br>
          More information on: <a href="https://ubicomp.eti.uni-siegen.de" target="_blank" rel="noopener">https://ubicomp.eti.uni-siegen.de</a>
          </p>
        </div>
      </div>

<!--
      <div class="speaker-info">
        <div class="speaker-image">
          <img src="./assets/images/TPloetz_cropped2.jpeg" alt="Thomas Ploetz" style="width: 100%; max-width: 300px;" />
        </div>
        <div class="speaker-details">
          <h2><a href="https://www.cc.gatech.edu/people/thomas-ploetz">Thomas Ploetz</a></h2>
          <p>Georgia Institute of Technology</p>
          <p><b>Title:</b> Computational Behavior Analysis for Wellbeing Assessments — Smart Entities (Devices, Algorithms, Humans) are Pushing the Boundaries of Digital Health.</p>
          <p><b>Abstract:</b> Many aspects of both mental and physical wellbeing are linked to a human's behavior and activities, i.e., what a person is doing and when, and how this changes over time. As such, human activity recognition using wearable and other pervasive sensing methods (HAR) is a pillar of mobile and ubiquitous computing based, out-of-clinic wellbeing assessments in various shapes and forms. Alas, recognizing what a person does is—to this day—a non-trivial endeavor due to the underlying analysis of multi-variate, noisy sensor data, which constitutes a formidable machine learning problem that the research community has been tackling.
          
          In this talk I will first summarize what makes HAR a hard machine learning problem and then discuss how recent technological breakthroughs can help to get closer to solving it. I will focus on opportunities to overcome data scarcity through cross-modality transfer, and self-supervised learning. I will then delve into some of the wellbeing assessments that my lab has been doing in areas such as Parkinson's assessment, automated analysis of eating behavior as proxy for mental wellbeing assessments, and recent work in behavior assessments for people with mild cognitive impairments.
            
          Finally, I will explore some more foundational thoughts on how we (should) characterize activities and behaviors and how language learning may help us to develop a more systematic and thus robust and generalizable understanding of human activities. I argue that human activities follow concepts that are similar to those of natural languages and as such these can be learnt, which will lead to improved modeling as well as analysis — as it is of importance, for example, for many medical applications.
         </p>
         <p style="text-align: justify;"><b>Bio:</b> Thomas Ploetz is a Computer Scientist with expertise and almost two decades of experience in Pattern Recognition and Machine Learning research (PhD from Bielefeld University, Germany). He works as a Professor of Computing at the School of Interactive Computing at the Georgia Institute of Technology in Atlanta, USA. His research agenda focuses on applied machine learning, that is developing systems and innovative sensor data analysis methods for real world applications. Primary application domain for his work is computational behavior analysis where he develops methods for automated and objective behavior assessments in naturalistic environments, thereby making opportunistic use of ubiquitous and wearable sensing methods. Main driving functions for his work are "in the wild" deployments and as such the development of systems and methods that have a real impact on people's lives.
          
          Thomas has been very active in the mobile and ubiquitous, including wearable computing community. He is co-editor in chief of the Proc. of the ACM on Interactive, Mobile, Wearable, and Ubiquitous computing technology (IMWUT), has twice been co-chair of the technical program committee of the International Symposium on Wearable Computing (ISWC), and was general co-chair of the 2022 Int. Joint Conf. On Pervasive and Ubiquitous Computing (Ubicomp). Thomas is a Distinguished Member of the ACM. More info <a href="http://thomasploetz.de">here</a>. </p>

      </div>

      <div class="speaker-info">
        <div class="speaker-image">
          <img src="./assets/images/yuntaowang.png" alt="Yuntao Wang" style="width: 100%; max-width: 300px;" />
        </div>
        <div class="speaker-details">
          <h2><a href="https://pi.cs.tsinghua.edu.cn/lab/people/YuntaoWang/en/">Yuntao Wang</a></h2>
          <p>Tsinghua University</p>
          <p><strong>Title</strong>: <b>Enabling Continuous Physiological Sensing on Ubiquitous Devices</b></p>
          <p style="text-align: justify;"><b>Abstract:</b> Personal health monitoring plays a pivotal role in reflecting lifestyle habits, detecting physical abnormalities, and tracking medical conditions and recovery statuses, thereby offering significant value for overall wellbeing. It is essential for integrating user-friendly and easily accessible healthcare services both inside and outside medical facilities, making it a key research area in human-computer interaction and ubiquitous computing. Traditionally, this field has relied heavily on medical-grade devices to collect physiological data, which are not only costly but also offer limited scalability, thus hindering their widespread use. This presentation will showcase our latest research efforts focused on achieving efficient and continuous physiological sensing with ubiquitous devices. Our goal is to provide new insights and innovative technological approaches within the realm of human-computer interaction for health.</p>
          <p style="text-align: justify;"><b><strong>Bio</strong>:</b> Yuntao Wang serves as an Associate Professor (Research Track) in the Department of Computer Science and Technology at Tsinghua University in Beijing, China. He is a key member of the Pervasive Interaction Lab, where his research focuses on Human-Computer Interaction (HCI) and Ubiquitous Computing. Dr. Wang specializes on efficient behavioral computing and interaction intention inference on edge devices. He has published more than 70 conference or journal papers including top-tier venues like CHI, IMWUT, UIST and NeurIPS, with seven of these papers earning best paper or honorable mentioned awards. Dr. Wang's research work has been recognized by the Young Elite Scientists Sponsorship Program by the China Association for Science and Technology (CAST) in 2022, the First Prize of Science and Technology Award of the Chinese Institute of Electronics (CIE) in 2019, the Excellent Innovation Award of the Chinese Association of Artificial Intelligence (CAAI) in 2021. More info <a href="https://pi.cs.tsinghua.edu.cn/lab/people/YuntaoWang/en/">here</a></p>

        </div>
      </div>
-->
    </main>
  </body> 
</html>
